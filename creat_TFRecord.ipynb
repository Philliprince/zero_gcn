{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/messor/.pyenv/versions/3.6.4/envs/shinerio-python3.6.4-env/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from random import shuffle\n",
    "\n",
    "from utils.data_analyze import *\n",
    "from utils.transform import *\n",
    "from dataset.test_data_loader import TestDataLoader\n",
    "from dataset.train_data_loader import TrainDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "# 生成字符串型的属性\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "# 生成实数型的属性\n",
    "def float_list_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-03 21:50:01,378 config:\n",
      "{'DEBUG': False,\n",
      " 'alpha': 0.99,\n",
      " 'data_loader_num_workers': 8,\n",
      " 'data_path': '/home/messor/data_center/object_classification/zero_sample_classification',\n",
      " 'dataset': {'b_g_r_mean': [108.74949161620336,\n",
      "                            121.93682191782138,\n",
      "                            129.882933212282],\n",
      "             'b_g_r_std': [76.27990887272082,\n",
      "                           72.2227214967396,\n",
      "                           73.87829834580016],\n",
      "             'className_classSymbol_list': ['/home/messor/data_center/object_classification/zero_sample_classification/DatasetA_train/label_list.txt'],\n",
      "             'className_wordEmbeddings_list': ['/home/messor/data_center/object_classification/zero_sample_classification/DatasetA_train/class_wordembeddings.txt',\n",
      "                                               '/home/messor/data_center/object_classification/zero_sample_classification/DatasetA_test/class_wordembeddings.txt'],\n",
      "             'classSymbol_attributes_list': ['/home/messor/data_center/object_classification/zero_sample_classification/DatasetA_train/attributes_per_class.txt',\n",
      "                                             '/home/messor/data_center/object_classification/zero_sample_classification/DatasetA_test/attributes_per_class.txt'],\n",
      "             'id_attribute_list': ['/home/messor/data_center/object_classification/zero_sample_classification/DatasetA_train/attribute_list.txt',\n",
      "                                   '/home/messor/data_center/object_classification/zero_sample_classification/DatasetA_test/attribute_list.txt'],\n",
      "             'input_resolution': [64, 64],\n",
      "             'testImageDirPath_list': ['/home/messor/data_center/object_classification/zero_sample_classification/DatasetA_test/test'],\n",
      "             'testImageName_list': ['/home/messor/data_center/object_classification/zero_sample_classification/DatasetA_test/image.txt'],\n",
      "             'testTFRecord_list': ['/home/messor/data_center/object_classification/zero_sample_classification/DatasetA_test/TFRecords'],\n",
      "             'trainImageDirPath_list': ['/home/messor/data_center/object_classification/zero_sample_classification/DatasetA_train/train'],\n",
      "             'trainImageName_classSymbol_list': ['/home/messor/data_center/object_classification/zero_sample_classification/DatasetA_train/train.txt'],\n",
      "             'trainTFRecord_list': ['/home/messor/data_center/object_classification/zero_sample_classification/DatasetA_train/TFRecords']},\n",
      " 'epoch': 60,\n",
      " 'epsilon': 1e-08,\n",
      " 'exp': '/home/messor/data_center/object_classification/zero_sample_classification/yuan.liu',\n",
      " 'log_path': '/home/messor/data_center/object_classification/zero_sample_classification/yuan.liu/2018-09-03/21_47_37_logs',\n",
      " 'lr_params': {'decay': 0.1,\n",
      "               'lr': 0.075,\n",
      "               'lr_step': [40, 55],\n",
      "               'warm_up': True,\n",
      "               'warm_up_epoch': 2,\n",
      "               'warm_up_lr': 0.001},\n",
      " 'model_path': '/home/messor/data_center/object_classification/zero_sample_classification/yuan.liu/2018-09-03/21_47_37_models',\n",
      " 'momentum': 0.0,\n",
      " 'network': 'ResNet#50',\n",
      " 'num_gpu': 1,\n",
      " 'out_classes': [24, 300],\n",
      " 'person_name': 'yuan.liu',\n",
      " 'project_name': 'zero_sample_classification',\n",
      " 'root_path': '/home/messor/data_center',\n",
      " 'sample_test': None,\n",
      " 'support_network': ['ResNet'],\n",
      " 'task_name': 'object_classification',\n",
      " 'test': {'aug_strategy': {'flip': False,\n",
      "                           'max_rotate_angle': 20,\n",
      "                           'normalize': True,\n",
      "                           'random_color': False,\n",
      "                           'random_crop': False,\n",
      "                           'random_rotate': False},\n",
      "          'batch_size': 1500},\n",
      " 'train': {'aug_strategy': {'flip': True,\n",
      "                            'max_rotate_angle': 20,\n",
      "                            'normalize': True,\n",
      "                            'random_color': False,\n",
      "                            'random_crop': False,\n",
      "                            'random_rotate': True},\n",
      "           'batch_size': 60,\n",
      "           'split_val': 0.2},\n",
      " 'weightDecay': 0.0}\n",
      "2018-09-03 21:50:01,379 merge 2 file, finally get 30 attributes\n",
      "2018-09-03 21:50:01,386 merge 2 file, finally get 230 class attributes\n",
      "2018-09-03 21:50:01,436 merge 2 file, finally get 230 pair of class name and wordembeddings\n",
      "2018-09-03 21:50:01,437 merge 1 file, finally get 230 real name labels\n",
      "2018-09-03 21:50:01,541 load train data from 1 data set, total item 38221\n",
      "2018-09-03 21:50:01,545 190 classes in train data, total 230, so there are 40 classes not exist in train data set\n",
      "2018-09-03 21:50:01,583 load test data from 1 data set, total item 14633\n"
     ]
    }
   ],
   "source": [
    "logger = create_logger(os.path.join(config.log_path, 'train.log'))\n",
    "logger.info('config:\\n{}'.format(pprint.pformat(config)))\n",
    "id_attribute_dict, classSymbol_attributes_dict, className_wordEmbeddings_dict, className_classSymbol_dict, train_class_symbol, train_image_path_list, test_image_path_list = get_all_data(logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_symbol = train_class_symbol[: config.sample_test]\n",
    "train_image_path_list = train_image_path_list[: config.sample_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classSymbol_wordEmbeddings_dict = replace_name_with_symbol(className_wordEmbeddings_dict, className_classSymbol_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = make_label(train_class_symbol, classSymbol_attributes_dict, classSymbol_wordEmbeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formate_train_class_num_list(train_class_symbol, className_classSymbol_dict):\n",
    "    train_class_id = []\n",
    "    classSymbol_id_dict = {}\n",
    "    for i, className_symbol in enumerate(className_classSymbol_dict):\n",
    "        classSymbol_id_dict[className_symbol] = i\n",
    "    return classSymbol_id_dict\n",
    "classSymbol_id_dict = formate_train_class_num_list(train_class_symbol, className_classSymbol_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_id = []\n",
    "for class_symbol in train_class_symbol:\n",
    "    train_class_id.append(classSymbol_id_dict[class_symbol])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_records(dataset_loader, image_path_list, class_symbol_list, output_record_dir):\n",
    "    writer = tf.python_io.TFRecordWriter(output_record_dir)\n",
    "    for i in range(len(image_path_list)):\n",
    "        image = dataset_loader.__getitem__(i)\n",
    "        image_raw = image.tostring()\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'image_raw': _bytes_feature(image_raw),\n",
    "            'height': _int64_feature(image.shape[0]),\n",
    "            'width': _int64_feature(image.shape[1]),\n",
    "            'depth': _int64_feature(image.shape[2]),\n",
    "            'label':  _int64_feature(class_symbol_list[i])\n",
    "        }))\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-03 22:27:27,127 using 6115 for test\n"
     ]
    }
   ],
   "source": [
    "if config.train.split_val is not None:\n",
    "    temp = list(zip(train_class_id, train_image_path_list, train_label))\n",
    "    shuffle(temp)\n",
    "    train_class_id, train_image_path_list, train_label = zip(*temp)\n",
    "    len_val = int(len(train_label) * config.train.split_val)\n",
    "\n",
    "    val_image_path_list = train_image_path_list[: len_val]\n",
    "    val_class_id = train_class_id[:len_val]\n",
    "    train_label = train_label[len_val:]\n",
    "    train_image_path_list = train_image_path_list[len_val:]\n",
    "    val_data_loader = TestDataLoader(config, val_image_path_list, val_class_id)\n",
    "\n",
    "    if not os.path.exists(config.dataset.trainTFRecord_list[0]):\n",
    "        os.makedirs(config.dataset.trainTFRecord_list[0])\n",
    "\n",
    "    val_record_dir = os.path.join(config.dataset.trainTFRecord_list[0], 'val.tfrecords')\n",
    "    creat_records(val_data_loader, val_image_path_list, val_class_id, val_record_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-03 22:28:37,724 using 24462 for train\n"
     ]
    }
   ],
   "source": [
    "train_data_loader = TrainDataLoader(train_image_path_list, train_label, config)\n",
    "\n",
    "if not os.path.exists(config.dataset.trainTFRecord_list[0]):\n",
    "    os.makedirs(config.dataset.trainTFRecord_list[0])\n",
    "train_record_dir = os.path.join(config.dataset.trainTFRecord_list[0], 'train.tfrecords')\n",
    "creat_records(train_data_loader, train_image_path_list, train_class_id, train_record_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
